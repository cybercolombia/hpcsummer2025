{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8db4d0d",
   "metadata": {
    "id": "d8db4d0d"
   },
   "source": [
    "# <center>Parallel computing: fundamentals </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed0c27b",
   "metadata": {},
   "source": [
    "## ========== Concurrent, parallel, and distributed computing ==========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407c787b",
   "metadata": {
    "id": "407c787b"
   },
   "source": [
    "## Concurrent computing\n",
    "Concurrency implies interruptibility. In concurrent computing, you have several tasks, but these tasks may not execute all the time because, from time to time, they need to wait for another task to finish. For example, a task of adding two numbers may have to wait for I/O operations to get the values it has to add and return the results.\n",
    "\n",
    "### Example: Pipeline in a processor\n",
    "A processor needs to carry out several steps every time it receives an instruction, and it usually has specialized units to carry out each step. For example:\n",
    "- Fetch the instruction (IF).\n",
    "- Decode the instruction (ID).\n",
    "- Execute the instruction (EX).\n",
    "- Read/write information in the memory (MEM).\n",
    "- Write the result back (WB).\n",
    "\n",
    "<figure>\n",
    "<img src=\"figures/Nopipeline.png\" style=\"width: 600px\"/>\n",
    "<figcaption align = \"center\"><span style=\"fontsize: 100px\">CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=140175</span></figcaption>\n",
    "</figure>\n",
    "    \n",
    "To prevent having its different units in an idle state while one of the units is carrying out its task, the work is pipelined:\n",
    "<figure>\n",
    "<img src=\"figures/Fivestagespipeline.png\" style=\"width: 450px\"/>\n",
    "<figcaption align = \"center\"><span style=\"fontsize: 100px\">CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=140175</span></figcaption>\n",
    "</figure>\n",
    "    \n",
    "Note that in a pipeline all units work at the same time, but do different jobs. We say that the processor is executing several jobs **concurrently**. \n",
    "    \n",
    "## Parallel computing\n",
    "In parallel computing, we have one or more tasks and use several computing units in the same device (node). Each of the computing units is capable of executing any task or part of a task, so we assign a whole task or part of a task to each unit. All computing units execute their assigned tasks at the same time, i.e. in *parallel*.\n",
    "\n",
    "<img src=\"figures/parallel_comp.png\" style=\"width: 350px\"/>\n",
    "\n",
    "## Distributed computing\n",
    "In distributed computing, we use several devices interconnected by a network. Each device can have one or more compute units. As in parallel computing, each device can execute tasks in parallel with the other, but the devices need now to communicate with one another to pass data between them through a network. As different devices might require to fetch or deliver data at particular moments, there has to be coordination in the communication between them. This coordination can be achieved by implementing a message-passing protocol.\n",
    "\n",
    "<img src=\"figures/distributed_comp.png\" style=\"width: 350px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47574fc",
   "metadata": {
    "id": "a47574fc"
   },
   "source": [
    "## ==================The CPU and Flynn's taxonomy ==================\n",
    "A central processing unit (CPU), or processor, is composed of 3 main parts: An arithmetic logic unit (ALU), or *core*, that performs arithmetic calculations on data. A memory unit that stores the instructions, the data to be processed, and the results of the computations, and a control unit that dictates which instructions to carry out next and what data to read from the memory.\n",
    "\n",
    "<img src=\"figures/CPU.png\" style=\"width: 400px\"/>\n",
    "\n",
    "The architectures used in parallel and distributed computing are extensions and variations of the CPU model that contain several compute units, some of which might share memory or a control unit. These devices are classified according to the way in which the compute units and the memory are connected among themselves. This classification is known as **Flynn's taxonomy**, proposed by Michael Flynn in its current form in 1972. A revision of Flynn's taxonomy was carried out later by Ralph Duncan to include pipelined vector processes. We present now some of the most common architectures.\n",
    "\n",
    "### Single instruction single data (SISD)\n",
    "In the SISD architecture, we have a single processor that executes instructions one at a time.\n",
    "\n",
    "<img src=\"figures/SISD.png\" style=\"width: 200px\"/>\n",
    "\n",
    "### Single instruction multiple data (SIMD)\n",
    "In this architecture, several cores share the same control unit. A single instruction is broadcasted to all the ALUs. The data is then partitioned and each processor executes the instruction using a different part of the data.\n",
    "\n",
    "<img src=\"figures/SIMD.png\" style=\"width: 500px\"/>\n",
    "\n",
    "### Multimple instruction multiple data (MIMD)\n",
    "This architecture consists of several processors, each one with its own control unit, so that they can perform different instructions in parallel. This is the most common architecture.\n",
    "\n",
    "<img src=\"figures/MIMD.png\" style=\"width: 700px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47275993",
   "metadata": {
    "id": "47275993"
   },
   "source": [
    "## Processes and threads\n",
    "\n",
    "A **process** is an instance of a program that is assigned to a device, along with the data needed and access to the shared memory. A process consists of the following:\n",
    "- A process ID assigned by the operating system.\n",
    "- Access to a section of the memory to read/write data (virtual address space). The code and the data are located in the memory.\n",
    "- One or more *threads* that execute the code.\n",
    "- IO handles.\n",
    "\n",
    "\n",
    "A **thread**  is the part of a process that executes the instructions. It has a program counter, a set of registers, and memory (stack) assigned to it to store instructions and data locally.\n",
    "\n",
    "<img src=\"figures/process.png\" style=\"width: 400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-interpretation",
   "metadata": {
    "id": "cosmetic-interpretation"
   },
   "source": [
    "## Fork-join model\n",
    "In the fork-join model, the code is divided into different regions. A region can be sequential or parallel, depending on the number of threads that are executed. In a sequential region, a single thread executes the code, while in a parallel region, multiple threads execute, usually the same code with different data.\n",
    "\n",
    "<img src=\"figures/fj_model.png\" style=\"width: 500px\"/>\n",
    "\n",
    "Sequential regions usually run code that cannot be parallelized because of strict dependencies between operations. Once a parallelizable region of the code is reached, a fork operation creates several threads and assigns a copy of the code, as well as a chunk of data, to each one. Once all threads have finished their jobs, a join operation retrieves the output data from each thread and destroys it, leaving a single thread in charge again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9132ca",
   "metadata": {
    "id": "fe9132ca"
   },
   "source": [
    "## =================== Example of parallelism ======================\n",
    "Now we proceed to look at a simple example of parallelism, in which we create multiple threads for a single process in order to perform a series of tasks in parallel.<br>\n",
    "\n",
    "Let's start by defining a simple task:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a6628",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`task1.py`\n",
    "```python\n",
    "from time import sleep\n",
    "\n",
    "def task(n):\n",
    "    print('Starting task {0}...'.format(n))\n",
    "    sleep(1)\n",
    "    print('Task {0}: done'.format(n))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f91c5",
   "metadata": {
    "id": "de4f91c5"
   },
   "source": [
    "### Single process, single thread\n",
    "We now execute the task a couple of times and measure how much time it takes for the process to complete, using the single thread it creates by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157817e",
   "metadata": {
    "id": "0c705bc4",
    "outputId": "f404443f-6895-43cd-8a6a-d652661af9f2"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "`example1.py`\n",
    "```python\n",
    "from time import perf_counter\n",
    "from task1 import task\n",
    "    \n",
    "start_time = perf_counter() #Clock with the highest available resolution\n",
    "\n",
    "task(0)\n",
    "task(1)\n",
    "\n",
    "end_time = perf_counter()\n",
    "\n",
    "print(\"Time: {0}\".format(end_time-start_time))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N1 -n1 --cpus-per-task=8 python code/example1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f7a41",
   "metadata": {
    "id": "bc0f7a41"
   },
   "source": [
    "### Single process, multiple threads\n",
    "Now, we proceed to ask the process to create more threads, and we assign to each one of them a single task to perform. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52834018",
   "metadata": {
    "id": "52834018"
   },
   "source": [
    "Two threads:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d2e310",
   "metadata": {
    "id": "b30a8ae0",
    "outputId": "6bfee963-8990-4dda-8f06-60e56bf02cee"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "    \n",
    "`example2.py`\n",
    "```python\n",
    "from time import perf_counter\n",
    "from threading import Thread\n",
    "from task1 import task\n",
    "    \n",
    "start_time = perf_counter()\n",
    "\n",
    "# Create two threads, each one with a task function\n",
    "t0 = Thread(target=task, args=(0,))\n",
    "t1 = Thread(target=task, args=(1,))\n",
    "\n",
    "# Start the threads\n",
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "# Wait for the threads to complete\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "end_time = perf_counter()\n",
    "\n",
    "print(\"Time: {0}\".format(end_time-start_time))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc6273",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N1 -n1 --cpus-per-task=8 python code/example2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd16a6",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b51633",
   "metadata": {
    "id": "54b51633"
   },
   "source": [
    "### Exercise 1\n",
    "Repeat the previous example but using eight threads (Hint: the Thread objects can be stored in a python list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4bee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N1 -n1 --cpus-per-task=8 python exercises/exercise1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c490bf6",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc18b14",
   "metadata": {
    "id": "abc18b14"
   },
   "source": [
    "Note that in the previous examples when launching $n$ threads the time reduction is almost $n$-fold. However, this level of efficiency can only be attained as long as the following requirements are met:\n",
    "- The tasks can be performed in a parallel fashion, that is, the input of a task is independent of the output of all others. \n",
    "- There are enough computing units to carry out each task simultaneously.\n",
    "- The time it takes for a task to complete is much longer than the time it takes to create, start and join a thread.\n",
    "\n",
    "If you execute the previous code cell several times you might note also that the threads do not necessarily complete their tasks in order, and in some cases, a thread might finish even before others have been started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff92d9",
   "metadata": {
    "id": "f9ff92d9"
   },
   "source": [
    "### Race conditions\n",
    "We will now observe what happens when the result of one task depends on the actions taken by other tasks. To do this we take a simple example: incrementing the value of a global (shared) variable $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab139c94",
   "metadata": {
    "id": "a0d039b1",
    "outputId": "315927e7-6781-4fe9-80cb-60367af25a0e"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`example3.py`\n",
    "```python\n",
    "from time import sleep, perf_counter\n",
    "\n",
    "x = 0\n",
    "\n",
    "def increment_variable(n):\n",
    "    global x\n",
    "        \n",
    "    sleep(1)\n",
    "    local_x = x\n",
    "    print(\"Task {0}: Adding 1 to x={1}\".format(n, x))\n",
    "    local_x += 1\n",
    "    x = local_x\n",
    "    print(\"Task {0}: Finished. x={1}\".format(n,x))\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "print(\"Initial x={0}\\n\".format(x))\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "for i in range(8):\n",
    "    increment_variable(i)\n",
    "\n",
    "end_time = perf_counter()\n",
    "\n",
    "print(\"\\nFinal x={0}\".format(x))\n",
    "print(\"Time: {0}\".format(end_time-start_time))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec7f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N1 -n1 --cpus-per-task=8 python code/example3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603605d",
   "metadata": {
    "id": "6603605d"
   },
   "source": [
    "The previous serial code works as expected, where the first task takes the current value of $x=0$, adds $1$ to obtain $x=1$, which is taken by the second task and is incremented to $2$ and so on, until the final task takes a $7$ and adds $1$ to get the final correct result $x=8$, in approximately 8 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc731e",
   "metadata": {
    "id": "81a3c5fe",
    "outputId": "9e25dcd9-dfe6-48e1-ed07-c29913f89aac"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`example4.py`\n",
    "```python\n",
    "from time import sleep, perf_counter\n",
    "from threading import Thread\n",
    "    \n",
    "x = 0\n",
    "\n",
    "def increment_variable(n):\n",
    "    global x\n",
    "        \n",
    "    sleep(1)\n",
    "    local_x = x\n",
    "    print(\"Task {0}: Adding 1 to x={1}\".format(n, x))\n",
    "    local_x += 1\n",
    "    x = local_x\n",
    "    print(\"Task {0}: Finished. x={1}\".format(n,x))\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "print(\"Initial x={0}\\n\".format(x))\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "# Create 8 threads, each one with a task function\n",
    "threads = []\n",
    "for i in range(8):\n",
    "    threads.append(Thread(target=increment_variable, args=(i,)))\n",
    "\n",
    "# Start the threads\n",
    "for thr in threads:\n",
    "    thr.start()\n",
    "\n",
    "# Wait for the threads to complete\n",
    "for thr in threads:\n",
    "    thr.join()\n",
    "\n",
    "end_time = perf_counter()\n",
    "\n",
    "print(\"\\nFinal x={0}\".format(x))\n",
    "print(\"Time: {0}\".format(end_time-start_time))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb229852",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N1 -n1 --cpus-per-task=8 python code/example4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe831b",
   "metadata": {
    "id": "5afe831b"
   },
   "source": [
    "By executing the previous cell multiple times you might find, perhaps with surprise, that in some cases the final result $x<8$ ! For example, we might observe the following output:<br><br>\n",
    "\n",
    "<pre><code>Initial x=0\n",
    "\n",
    "Task 0: Adding 1 to x=0Task 1: Adding 1 to x=0\n",
    "Task 1: Finished. x=1\n",
    "Task 2: Adding 1 to x=1\n",
    "Task 2: Finished. x=2\n",
    "Task 5: Adding 1 to x=2\n",
    "Task 5: Finished. x=3\n",
    "Task 3: Adding 1 to x=3\n",
    "Task 3: Finished. x=4\n",
    "Task 4: Adding 1 to x=4\n",
    "Task 4: Finished. x=5\n",
    "\n",
    "Task 0: Finished. x=1\n",
    "Task 6: Adding 1 to x=1\n",
    "Task 6: Finished. x=2\n",
    "Task 7: Adding 1 to x=2\n",
    "Task 7: Finished. x=3\n",
    "\n",
    "Final x=3\n",
    "Time: 1.0039066870231181\n",
    "</code></pre>\n",
    "\n",
    "We obtained the result in 1/8 of the time it took the serial code to run, but the result is incorrect. Why is this? <br>\n",
    "\n",
    "By looking carefully at the output we see that threads 0 and 1 started first and both took as input an initial value $x=0$, added $1$, and wrote the result $1$ back to $x$. Note that by this point two tasks have been executed but $x=1$, when it should have been $2$. In a similar way, threads 2 and 6 take $x$ as input when its value is $1$ and write back a value $x=2$, so 4 tasks have been executed already and the result is $x=2$, when it should have been $4$.<br>\n",
    "\n",
    "The problem lies then in the possibility of having more than one thread updating the shared variable at the same time. This kind of problem is called a *race condition*, as the threads compete to get first to a shared variable and modify it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1032419",
   "metadata": {
    "id": "e1032419"
   },
   "source": [
    "### Thread lock\n",
    "In order to prevent more than one thread from accessing the same memory space at the same time, we can *lock* a section of code. Only a single thread can be executing a *locked* section of code at the same time, meaning that the other threads have to wait until the current thread is finished to be able to execute it themselves.<br>\n",
    "\n",
    "We will create a Lock object and use it to lock the code inside the increment_variable function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17aeec6",
   "metadata": {
    "id": "fb3e9aa4",
    "outputId": "624f0d7d-4d90-4405-d147-c2eba3f84c88"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "`example5.py`\n",
    "```python\n",
    "from time import sleep, perf_counter\n",
    "from threading import Thread, Lock\n",
    "\n",
    "x = 0\n",
    "\n",
    "def increment_variable(n, lock):\n",
    "    global x\n",
    "    \n",
    "    lock.acquire() #Start of the locked region\n",
    "    \n",
    "    sleep(1)\n",
    "    local_x = x\n",
    "    print(\"Task {0}: Adding 1 to x={1}\".format(n, x))\n",
    "    local_x += 1\n",
    "    x = local_x\n",
    "    print(\"Task {0}: Finished. x={1}\".format(n,x))\n",
    "\n",
    "    lock.release() #End of the locked region\n",
    "    \n",
    "#------------------------------------------------------------------\n",
    "print(\"Initial x={0}\\n\".format(x))\n",
    "\n",
    "#create Lock object\n",
    "lock = Lock()\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "# Create 8 threads, each one with a task function\n",
    "threads = []\n",
    "for i in range(8):\n",
    "    threads.append(Thread(target=increment_variable, args=(i,lock)))\n",
    "\n",
    "# Start the threads\n",
    "for thr in threads:\n",
    "    thr.start()\n",
    "\n",
    "# Wait for the threads to complete\n",
    "for thr in threads:\n",
    "    thr.join()\n",
    "\n",
    "end_time = perf_counter()\n",
    "\n",
    "print(\"\\nFinal x={0}\".format(x))\n",
    "print(\"Time: {0}\".format(end_time-start_time))\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N1 -n1 --cpus-per-task=8 python code/example5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4ac65",
   "metadata": {
    "id": "d5d4ac65"
   },
   "source": [
    "We see now that the code gives the correct output every time, but it takes the same time as the serial code, which beats the purpose of our parallelization. The reason why this happens is that we have included all the code of the function in the locked region, and the threads have to wait for a full second every time another thread enters the locked region. If we manage to keep just the critical section of code where the race condition is present, we might get back some of the efficiency of our parallelization.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b0beb8",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90439df5",
   "metadata": {
    "id": "90439df5"
   },
   "source": [
    "### Exercise 2\n",
    "Taking out of the locked region all the code that does not present a race condition problem and reduce the execution time, while ensuring the correctness of the result! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35cd23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N1 -n1 --cpus-per-task=8 python exercises/exercise2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0739979b",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hpcssenv",
   "language": "python",
   "name": "hpcssenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
